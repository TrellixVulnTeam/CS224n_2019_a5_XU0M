{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path, source):\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
    "        is of the source language or target language\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = line.strip().split(' ')\n",
    "        # only append <s> and </s> to the target sentence\n",
    "        if source == 'tgt':\n",
    "            sent = ['<s>'] + sent + ['</s>']\n",
    "        data.append(sent)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tpython run.py train --train-src=./en_es_data/train_tiny.es --train-tgt=./en_es_data/train_tiny.en \\\n",
    "#         --dev-src=./en_es_data/dev_tiny.es --dev-tgt=./en_es_data/dev_tiny.en --vocab=vocab_tiny_q1.json --batch-size=2 \\\n",
    "#         --valid-niter=100 --max-epoch=101 --no-char-decoder\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "from docopt import docopt\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from nmt_model import Hypothesis, NMT\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "from tqdm import tqdm\n",
    "from utils import read_corpus, batch_iter\n",
    "from vocab import Vocab, VocabEntry\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils\n",
    "    \n",
    "args = {}\n",
    "args['--train-src'] = './en_es_data/train_tiny.es'\n",
    "args['--train-tgt'] = './en_es_data/train_tiny.en'\n",
    "args['--dev-src'] = './en_es_data/dev_tiny.es'\n",
    "args['--dev-tgt'] = './en_es_data/dev_tiny.en'\n",
    "args['--vocab'] = 'vocab_tiny_q1.json'\n",
    "args['--batch-size'] =  2\n",
    "args['--valid-niter'] = 100\n",
    "args['--max-epoch'] = 101\n",
    "args['--clip-grad'] = 5\n",
    "args['--valid-niter'] = 2000\n",
    "args['--log-every'] = 10\n",
    "args['--save-to'] = 'model.bin'\n",
    "args['--vocab'] = 'vocab.json'\n",
    "args['--embed-size'] = 256\n",
    "args['--hidden-size'] = 256\n",
    "args['--dropout'] = 0.3\n",
    "args['--no-char-decoder'] = True\n",
    "args['--uniform-init'] = 0.1\n",
    "args['--cuda'] = None\n",
    "args['--lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_src = read_corpus(args['--train-src'], source='src')\n",
    "train_data_tgt = read_corpus(args['--train-tgt'], source='tgt')\n",
    "\n",
    "dev_data_src = read_corpus(args['--dev-src'], source='src')\n",
    "dev_data_tgt = read_corpus(args['--dev-tgt'], source='tgt')\n",
    "\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "dev_data = list(zip(dev_data_src, dev_data_tgt))\n",
    "\n",
    "train_batch_size = int(args['--batch-size'])\n",
    "\n",
    "clip_grad = float(args['--clip-grad'])\n",
    "valid_niter = int(args['--valid-niter'])\n",
    "log_every = int(args['--log-every'])\n",
    "model_save_path = args['--save-to']\n",
    "\n",
    "vocab = Vocab.load(args['--vocab'])\n",
    "\n",
    "model = NMT(embed_size=int(args['--embed-size']),\n",
    "            hidden_size=int(args['--hidden-size']),\n",
    "            dropout_rate=float(args['--dropout']),\n",
    "            vocab=vocab, no_char_decoder=args['--no-char-decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMT(\n",
       "  (model_embeddings_source): ModelEmbeddings(\n",
       "    (embeddings): Embedding(96, 50, padding_idx=0)\n",
       "    (cnn_layer): CNN(\n",
       "      (cnn_layer): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "      (max_pool_layer): MaxPool1d(kernel_size=17, stride=17, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (highway_layer): Highway(\n",
       "      (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (dropout_layer): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (model_embeddings_target): ModelEmbeddings(\n",
       "    (embeddings): Embedding(96, 50, padding_idx=0)\n",
       "    (cnn_layer): CNN(\n",
       "      (cnn_layer): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
       "      (max_pool_layer): MaxPool1d(kernel_size=17, stride=17, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (highway_layer): Highway(\n",
       "      (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (gate): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (dropout_layer): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (encoder): LSTM(256, 256, bidirectional=True)\n",
       "  (decoder): LSTMCell(512, 256)\n",
       "  (h_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (c_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (att_projection): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (combined_output_projection): Linear(in_features=768, out_features=256, bias=False)\n",
       "  (target_vocab_projection): Linear(in_features=256, out_features=50002, bias=False)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin Maximum Likelihood training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uniformly initialize parameters [-0.100000, +0.100000]\n",
      "use device: cpu\n"
     ]
    }
   ],
   "source": [
    "uniform_init = float(args['--uniform-init'])\n",
    "if np.abs(uniform_init) > 0.:\n",
    "    print('uniformly initialize parameters [-%f, +%f]' % (uniform_init, uniform_init), file=sys.stderr)\n",
    "    for p in model.parameters():\n",
    "        p.data.uniform_(-uniform_init, uniform_init)\n",
    "\n",
    "vocab_mask = torch.ones(len(vocab.tgt))\n",
    "vocab_mask[vocab.tgt['<pad>']] = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if args['--cuda'] else \"cpu\")\n",
    "print('use device: %s' % device, file=sys.stderr)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(args['--lr']))\n",
    "\n",
    "num_trial = 0\n",
    "train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
    "cum_examples = report_examples = epoch = valid_num = 0\n",
    "hist_valid_scores = []\n",
    "train_time = begin_time = time.time()\n",
    "print('begin Maximum Likelihood training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wunengzi/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/wunengzi/Documents/CS224n2019/a5_public/nmt_model.py:287: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:570.)\n",
      "  e_t.data.masked_fill_(enc_masks.byte(), -float('inf'))\n"
     ]
    }
   ],
   "source": [
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=train_batch_size, shuffle=True):\n",
    "    train_iter += 1\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_size = len(src_sents)\n",
    "\n",
    "    example_losses = -model(src_sents, tgt_sents) # (batch_size,)\n",
    "    batch_loss = example_losses.sum()\n",
    "    loss = batch_loss / batch_size\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # clip gradient\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    batch_losses_val = batch_loss.item()\n",
    "    report_loss += batch_losses_val\n",
    "    cum_loss += batch_losses_val\n",
    "\n",
    "    tgt_words_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n",
    "    report_tgt_words += tgt_words_num_to_predict\n",
    "    cum_tgt_words += tgt_words_num_to_predict\n",
    "    report_examples += batch_size\n",
    "    cum_examples += batch_size\n",
    "\n",
    "    if train_iter % log_every == 0:\n",
    "        print('epoch %d, iter %d, avg. loss %.2f, avg. ppl %.2f ' \\\n",
    "              'cum. examples %d, speed %.2f words/sec, time elapsed %.2f sec' % (epoch, train_iter,\n",
    "                                                                                 report_loss / report_examples,\n",
    "                                                                                 math.exp(report_loss / report_tgt_words),\n",
    "                                                                                 cum_examples,\n",
    "                                                                                 report_tgt_words / (time.time() - train_time),\n",
    "                                                                                 time.time() - begin_time), file=sys.stderr)\n",
    "\n",
    "        train_time = time.time()\n",
    "        report_loss = report_tgt_words = report_examples = 0.\n",
    "\n",
    "    # perform validation\n",
    "    if train_iter % valid_niter == 0:\n",
    "        print('epoch %d, iter %d, cum. loss %.2f, cum. ppl %.2f cum. examples %d' % (epoch, train_iter,\n",
    "                                                                                 cum_loss / cum_examples,\n",
    "                                                                                 np.exp(cum_loss / cum_tgt_words),\n",
    "                                                                                 cum_examples), file=sys.stderr)\n",
    "\n",
    "        cum_loss = cum_examples = cum_tgt_words = 0.\n",
    "        valid_num += 1\n",
    "\n",
    "        print('begin validation ...', file=sys.stderr)\n",
    "\n",
    "        # compute dev. ppl and bleu\n",
    "        dev_ppl = evaluate_ppl(model, dev_data, batch_size=128)   # dev batch size can be a bit larger\n",
    "        valid_metric = -dev_ppl\n",
    "\n",
    "        print('validation: iter %d, dev. ppl %f' % (train_iter, dev_ppl), file=sys.stderr)\n",
    "\n",
    "        is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
    "        hist_valid_scores.append(valid_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sents = read_corpus(args['--train-src'], source='src')\n",
    "tgt_sents = read_corpus(args['--train-tgt'], source='tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'so',\n",
       " 'much,',\n",
       " 'Chris.',\n",
       " 'And',\n",
       " \"it's\",\n",
       " 'truly',\n",
       " 'a',\n",
       " 'great',\n",
       " 'honor',\n",
       " 'to',\n",
       " 'have',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'this',\n",
       " 'stage',\n",
       " 'twice;',\n",
       " \"I'm\",\n",
       " 'extremely',\n",
       " 'grateful.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif [ \"$1\" = \"test_local_q1\" ]; then\n",
    "mkdir -p outputs\n",
    "touch outputs/test_outputs_local_q1.txt\n",
    "python run.py decode model.bin ./en_es_data/test_tiny.es ./en_es_data/test_tiny.en outputs/test_outputs_local_q1.txt \\\n",
    "    --no-char-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "from model_embeddings import ModelEmbeddings\n",
    "from char_decoder import CharDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(model: NMT, test_data_src: List[List[str]], beam_size: int, max_decoding_time_step: int) -> List[List[Hypothesis]]:\n",
    "    \"\"\" Run beam search to construct hypotheses for a list of src-language sentences.\n",
    "    @param model (NMT): NMT Model\n",
    "    @param test_data_src (List[List[str]]): List of sentences (words) in source language, from test set.\n",
    "    @param beam_size (int): beam_size (# of hypotheses to hold for a translation at every step)\n",
    "    @param max_decoding_time_step (int): maximum sentence length that Beam search can produce\n",
    "    @returns hypotheses (List[List[Hypothesis]]): List of Hypothesis translations for every source sentence.\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()a\n",
    "\n",
    "    hypotheses = []\n",
    "    with torch.no_grad():\n",
    "        for src_sent in tqdm(test_data_src, desc='Decoding', file=sys.stdout):\n",
    "            example_hyps = model.beam_search(src_sent, beam_size=beam_size, max_decoding_time_step=max_decoding_time_step)\n",
    "\n",
    "            hypotheses.append(example_hyps)\n",
    "\n",
    "    if was_training: model.train(was_training)\n",
    "\n",
    "    return hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(args: Dict[str, str]):\n",
    "    \"\"\" Performs decoding on a test set, and save the best-scoring decoding results.\n",
    "    If the target gold-standard sentences are given, the function also computes\n",
    "    corpus-level BLEU score.\n",
    "    @param args (Dict): args from cmd line\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"load test source sentences from [{}]\".format(args['TEST_SOURCE_FILE']), file=sys.stderr)\n",
    "    test_data_src = read_corpus(args['TEST_SOURCE_FILE'], source='src')\n",
    "    if args['TEST_TARGET_FILE']:\n",
    "        print(\"load test target sentences from [{}]\".format(args['TEST_TARGET_FILE']), file=sys.stderr)\n",
    "        test_data_tgt = read_corpus(args['TEST_TARGET_FILE'], source='tgt')\n",
    "\n",
    "    print(\"load model from {}\".format(args['MODEL_PATH']), file=sys.stderr)\n",
    "    model = NMT.load(args['MODEL_PATH'], no_char_decoder=args['--no-char-decoder'])\n",
    "\n",
    "    if args['--cuda']:\n",
    "        model = model.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "    hypotheses = beam_search(model, test_data_src,\n",
    "                             beam_size=int(args['--beam-size']),\n",
    "                             max_decoding_time_step=int(args['--max-decoding-time-step']))\n",
    "\n",
    "    if args['TEST_TARGET_FILE']:\n",
    "        top_hypotheses = [hyps[0] for hyps in hypotheses]\n",
    "        bleu_score = compute_corpus_level_bleu_score(test_data_tgt, top_hypotheses)\n",
    "        print('Corpus BLEU: {}'.format(bleu_score * 100), file=sys.stderr)\n",
    "\n",
    "    with open(args['OUTPUT_FILE'], 'w') as f:\n",
    "        for src_sent, hyps in zip(test_data_src, hypotheses):\n",
    "            top_hyp = hyps[0]\n",
    "            hyp_sent = ' '.join(top_hyp.value)\n",
    "            f.write(hyp_sent + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_src = read_corpus('./en_es_data/test_tiny.es', source = 'src')\n",
    "test_data_tgt = read_corpus('./en_es_data/test_tiny.en', source = 'tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMT.load('model.bin', no_char_decoder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding:  50%|█████     | 2/4 [00:00<00:00, 17.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wunengzi/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 4/4 [00:00<00:00, 16.45it/s]\n"
     ]
    }
   ],
   "source": [
    "hypotheses = beam_search(model, test_data_src,\n",
    "                         beam_size = 5,\n",
    "                         max_decoding_time_step=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Hypothesis(value=[\"It's\"], score=-2.5637383460998535),\n",
       "  Hypothesis(value=[\"It's\", 'a', 'a', 'true', 'Tipper', 'and', 'like', 'a', 'for', 'for', 'me.'], score=-5.935949325561523),\n",
       "  Hypothesis(value=[\"It's\", 'a', 'a', 'true', 'story', '--', 'and', 'all', 'of', 'a', 'for', 'for', 'me.'], score=-6.5942606925964355),\n",
       "  Hypothesis(value=[\"It's\", 'a', 'a', 'a', 'true', 'story', '--', 'and', 'all', 'of', 'a', 'for', 'for', 'me.'], score=-7.084736347198486),\n",
       "  Hypothesis(value=[\"It's\", 'a', 'a', 'a', 'true', 'story', '--', 'and', 'all', 'of', 'a', 'a', 'for', 'me.'], score=-7.09389066696167)],\n",
       " [Hypothesis(value=['Soon', 'after', 'Tipper'], score=-2.709735631942749),\n",
       "  Hypothesis(value=['Soon', 'after'], score=-3.7327487468719482),\n",
       "  Hypothesis(value=['Soon', 'after', 'Tipper', 'and', 'like', 'a', 'a', 'for', 'me.'], score=-4.965090274810791),\n",
       "  Hypothesis(value=['Soon', 'after', 'Tipper', 'and', 'like', 'a', 'a', 'little', 'farm', 'we', '(Mock', 'sob)', 'sob)', 'I', 'after', 'Tipper', 'and', 'like', 'a', 'Nashville.'], score=-12.825675010681152),\n",
       "  Hypothesis(value=['Soon', 'after', 'Tipper', 'and', 'like', 'a', 'a', 'little', 'farm', 'we', '(Mock', 'sob)', 'sob)', 'I', 'after', 'Tipper', 'and', 'like', 'a', 'a', 'for', 'me.'], score=-15.108580589294434)],\n",
       " [Hypothesis(value=['Driving', 'ourselves.'], score=-0.09416860342025757),\n",
       "  Hypothesis(value=['Driving'], score=-3.6334872245788574),\n",
       "  Hypothesis(value=['Driving', 'to', 'ourselves.'], score=-4.287264823913574),\n",
       "  Hypothesis(value=['Driving', 'Driving'], score=-4.981076240539551),\n",
       "  Hypothesis(value=['Driving', 'Driving', 'ourselves.'], score=-5.06010103225708)],\n",
       " [Hypothesis(value=['I', 'I', 'flew'], score=-2.1463592052459717)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0829, -0.0682,  0.0369,  ..., -0.0071,  0.0592,  0.0172],\n",
       "        [-0.0831, -0.0380, -0.1022,  ...,  0.0492,  0.0313,  0.0256],\n",
       "        [ 0.0395,  0.0201,  0.0406,  ...,  0.0139,  0.0140,  0.1094],\n",
       "        ...,\n",
       "        [-0.0237, -0.0783, -0.0273,  ..., -0.0010, -0.0431, -0.0818],\n",
       "        [-0.0031, -0.0827, -0.0044,  ..., -0.0512,  0.0486,  0.0773],\n",
       "        [-0.0082,  0.0594,  0.0419,  ...,  0.0268, -0.0039,  0.0971]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_embeddings_source.embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from docopt import docopt\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "from tqdm import tqdm\n",
    "from utils import pad_sents_char, read_corpus, batch_iter\n",
    "from vocab import Vocab, VocabEntry\n",
    "\n",
    "from char_decoder import CharDecoder\n",
    "from nmt_model import NMT\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0\n",
    "\n",
    "\n",
    "class DummyVocab():\n",
    "    def __init__(self):\n",
    "        self.char2id = json.load(open('./sanity_check_en_es_data/char_vocab_sanity_check.json', 'r'))\n",
    "        self.id2char = {id: char for char, id in self.char2id.items()}\n",
    "        self.char_unk = self.char2id['<unk>']\n",
    "        self.start_of_word = self.char2id[\"{\"]\n",
    "        self.end_of_word = self.char2id[\"}\"]\n",
    "        \n",
    "char_vocab = DummyVocab()\n",
    "        \n",
    "decoder = CharDecoder(\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    char_embedding_size=EMBED_SIZE,\n",
    "    target_vocab=char_vocab)\n",
    "\n",
    "model = NMT(\n",
    "        embed_size=EMBED_SIZE,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "sequence_length = 4\n",
    "inpt = torch.randint(high = 10,size=(sequence_length, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = inpt[:-1]\n",
    "target_sequence = inpt[1:]\n",
    "\n",
    "dec_hiddens = (torch.rand(1, BATCH_SIZE, HIDDEN_SIZE),torch.rand(1, BATCH_SIZE, HIDDEN_SIZE))\n",
    "scores, dec_hidden = decoder.forward(input_sequence, dec_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, char_embedding_size=50, target_vocab=None):\n",
    "        \"\"\" Init Character Decoder.\n",
    "\n",
    "        @param hidden_size (int): Hidden size of the decoder LSTM\n",
    "        @param char_embedding_size (int): dimensionality of character embeddings\n",
    "        @param target_vocab (VocabEntry): vocabulary for the target language. See vocab.py for documentation.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE for part 2a\n",
    "        ### TODO - Initialize as an nn.Module.\n",
    "        ###      - Initialize the following variables:\n",
    "        ###        self.charDecoder: LSTM. Please use nn.LSTM() to construct this.\n",
    "        ###        self.char_output_projection: Linear layer, called W_{dec} and b_{dec} in the PDF\n",
    "        ###        self.decoderCharEmb: Embedding matrix of character embeddings\n",
    "        ###        self.target_vocab: vocabulary for the target language\n",
    "        ###\n",
    "        ### Hint: - Use target_vocab.char2id to access the character vocabulary for the target language.\n",
    "        ###       - Set the padding_idx argument of the embedding matrix.\n",
    "        ###       - Create a new Embedding layer. Do not reuse embeddings created in Part 1 of this assignment.\n",
    "        super(CharDecoder, self).__init__()\n",
    "\n",
    "        V = len(target_vocab.char2id)\n",
    "        self.charDecoder = nn.LSTM(input_size = char_embedding_size, hidden_size = hidden_size)\n",
    "        self.char_output_projection = nn.Linear(in_features = hidden_size, out_features = V)\n",
    "        self.decoderCharEmb = nn.Embedding(num_embeddings = V, embedding_dim= char_embedding_size)\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def forward(self, input, dec_hidden=None):\n",
    "        \"\"\" Forward pass of character decoder.\n",
    "\n",
    "        @param input: tensor of integers, shape (length, batch)\n",
    "        @param dec_hidden: internal state of the LSTM before reading the input characters. A tuple of two tensors of shape (1, batch, hidden_size)\n",
    "\n",
    "        @returns scores: called s_t in the PDF, shape (length, batch, self.vocab_size)\n",
    "        @returns dec_hidden: internal state of the LSTM after reading the input characters. A tuple of two tensors of shape (1, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE for part 2b\n",
    "        ### TODO - Implement the forward pass of the character decoder.\n",
    "\n",
    "        char_embeddings = self.decoderCharEmb(input) # (length, batch, char_embedding_size)\n",
    "        hiddens, dec_hidden = self.charDecoder(char_embeddings, dec_hidden) # See documentation. Takes in (input, (h_0,c_0)) and produces (output, (h_t,c_t))\n",
    "        scores = self.char_output_projection(hiddens)\n",
    "\n",
    "        return scores, dec_hidden\n",
    "    \n",
    "decoder = CharDecoder(hidden_size = HIDDEN_SIZE, target_vocab = char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores, dec_hidden = decoder.forward(input_sequence, dec_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction = 'sum', ignore_index=decoder.target_vocab.char2id['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected target size (3, 30), got torch.Size([3, 5])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-d34c2e39f5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 948\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 2228\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   2229\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (3, 30), got torch.Size([3, 5])"
     ]
    }
   ],
   "source": [
    "loss(scores, target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3, 5, 30]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequence.shape, scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 30])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.view(-1, scores.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = torch.zeros(1, BATCH_SIZE, HIDDEN_SIZE, dtype=torch.float)\n",
    "initialStates = (inpt, inpt)\n",
    "device = decoder.char_output_projection.weight.device\n",
    "# decodedWords = decoder.decode_greedy(initialStates, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_t, cell_t = initialStates\n",
    "output_word = []\n",
    "current_char = '{'\n",
    "softmax_layer = nn.Softmax()\n",
    "max_length = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([decoder.target_vocab.char2id[current_char]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = decoder.target_vocab.char2id[current_char]\n",
    "end_index = decoder.target_vocab.char2id['}']\n",
    "\n",
    "inputs = torch.tensor([start_index for _ in range(BATCH_SIZE)], device = device).unsqueeze(0)\n",
    "decodedWords = []\n",
    "\n",
    "for t in range(max_length):\n",
    "    scores, (hidden_t, cell_t) = decoder.forward(inputs, (hidden_t, cell_t))\n",
    "\n",
    "    # For as long as our max_length is, push each sentence in the batch through charDecoder. So we should end up\n",
    "    # Scores = (1, batch_size, char_dim)\n",
    "\n",
    "    inputs = torch.argmax(scores, dim = 2) # Collapse char_dim, pick highest probability character\n",
    "    # current_chars has (1, batch_size), want to add to each in inputs\n",
    "    current_chars = [decoder.target_vocab.id2char[i.item()] for i in inputs[0]] # Pull out the next character\n",
    "    if t == 0:\n",
    "        words = current_chars\n",
    "    else:\n",
    "        words = [x + y for x, y in zip(words, current_chars)]\n",
    "\n",
    "# Now decodedWords is (max_length, batch_size). Slice it so that if } is reached, stop.\n",
    "for word in words:\n",
    "    if '}' in word:\n",
    "        word = word[word.index('}')]\n",
    "    decodedWords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.detach().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
