{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugger.ipynb          gpu_requirements.txt    run.sh\r\n",
      "Written.ipynb           highway.py              sanity_check.py\r\n",
      "__init__.py             local_env.yml           \u001b[34msanity_check_en_es_data\u001b[m\u001b[m\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m             model.bin               utils.py\r\n",
      "a5.pdf                  model.bin.optim         \u001b[34mvenv\u001b[m\u001b[m\r\n",
      "char_decoder.py         model_embeddings.py     vocab.json\r\n",
      "cnn.py                  nmt_model.py            vocab.py\r\n",
      "collect_submission.sh   \u001b[34moutputs\u001b[m\u001b[m                 vocab_tiny_q1.json\r\n",
      "\u001b[34men_es_data\u001b[m\u001b[m              run.py                  vocab_tiny_q2.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'r') as j:\n",
    "     contents = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(a) - which of the six words appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('traducir', True),\n",
       " ('traduzco', False),\n",
       " ('traduces', False),\n",
       " ('traduce', True),\n",
       " ('traduzca', False),\n",
       " ('traduzcas', False)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_words = contents['src_word2id']\n",
    "words_of_interest = ['traducir','traduzco','traduces','traduce','traduzca','traduzcas']\n",
    "\n",
    "[(i,i in spanish_words) for i in words_of_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no good because anything that isn't in the vocab, like traduzco, will be transferred to 'UNK'.\n",
    "The hope is that the character level decoder can rely on graphemic structures, e.g. figuring out which lemma to use when it encounters such a situation in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(b). https://projector.tensorflow.org/\n",
    "\n",
    "financial - economic  \n",
    "neuron - nerve  \n",
    "Francisco - san  \n",
    "naturally - occuring  \n",
    "expectation - norms  \n",
    "\n",
    "With the character level embeddings we have\n",
    "financial - vertical  \n",
    "neuron - Newton  \n",
    "Francisco - France  \n",
    "naturally - practically    \n",
    "expectation - exception\n",
    "\n",
    "It seems like Word2Vec models context (e.g you'd expect financial and employment to appear in the same contexts, while the charCNN models similarity based on context and also how similar the words are structurally/literally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
